title: How to standardize Data Science ways of working to unlock your team's creativity
---
author: Eric J. Ma
---
body:

Today, I had the opportunity to speak at BioIT World about my experiences leading a data science team at Moderna. Unlike most speakers, I ditched the slides and went for a more interactive approach – that's just my style. Why subject everyone to 25 minutes of me blabbering when we could have an engaging discussion instead?

For those who couldn't attend, I wanted to share the key insights from my talk on how we've made our data science team fly at Moderna. These lessons come from my experience as a data science team lead, where my teammates and I (a total of 6 of us) serve Moderna's 600-ish person research organization.

## The Mission

First, a bit about us: our team's mission is to "make science run at the speed of thought and to quantify the unquantified." I joined Moderna in summer 2021 – too late to profit from the pandemic, so I'm really there for the science, not the money!

## Talk Overview

In my talk, I focused on three key aspects of standardizing data science workflows:

1. How to design delivery models that truly serve stakeholder needs
2. Ways to make best practices the path of least resistance
3. Strategies for implementing standards without causing resistance

I shared concrete examples from my experience at Moderna, but also encouraged the audience to discuss these topics with their neighbors so we could learn from the collective wisdom in the room. My goal was for everyone to leave with practical ideas they could implement right away—regardless of their team or org size.

### 1. Standardized Delivery Models

The first thing to address is the question: what exactly does your data science team deliver? And I don't mean "insights" – that's not a specific enough answer. I'm talking about concrete work products.

Before choosing delivery formats, it's essential to understand the "jobs to be done" (from Clayton Christensen's Innovator's Solution) – what are stakeholders actually trying to accomplish with your outputs? Delivery models should be tailored to what your company actually needs, not just what's trendy.

At Moderna, we deliver two things as a data science team:

- **Python packages**: Reusable components that encapsulate data science work that other computational and data scientists can reuse.
- **Compute tasks**: CLI tools that serve as a wrapper for computational workflows, which are deployed on the cloud and accessible via web UI, RESTful API, and Python client. These serve both technical and non-technical users.

We made this decision early on to avoid building things like dashboards, which in my opinion are where data science projects go to die. Dashboards should be built by the people who actually want to see the data.

Instead, we chose these two things as our "delivery endpoints" because we knew that they were both concrete enough to standardize on while still being flexible enough to customize. A CLI tool (especially skinned for the web) and a Python package can do anything you program it to do, and yet both have simplicity in the skill level demanded by our computational/data scientists. (We do not need to know how to build UIs, for example.)

There is a strong "software engineering" component to our work, because we want to reduce the friction that occurs from handover. Every data scientist must understand that our return on investment is only realized if we package our work as software. I don't care if you know how to build a fancy Transformer ML model in a Jupyter notebook. If your work cannot be operationalized hands-free without your involvement, you have not delivered a return on investment in your time. Software is how we scale labor.

The benefits? Consistency, reusability, and very clear paths from exploration to production. Expectations with stakeholders are crystal clear, yet what we deliver is flexible enough to work with a variety of collaborators.

### 2. Making Best Practices the Path of Least Resistance

Consistent organization and automation reduces cognitive load and frees up mental energy for creative problem-solving. Our philosophy is simple: "Make the right thing the easy thing to do."

We've implemented several tactical best practices that make a big difference:

- **One project, one code repository**: Every project gets its own code repository – you can break this rule when you know the rule, but it's a good starting point.
- **Standardized project scaffolding**: We've invested in command-line tools (not unlike `pyds-cli`) that, after a quick questionnaire, generate a full Python project package structure with:
    - Dedicated locations for tests (signaling that testing is expected)
    - Documentation templates (encouraging thorough documentation)
    - Proper code organization into submodules
    - Configuration files
    - Pre-configured CI/CD pipelines that run on every commit
- **Automated workflows** that reduce friction:
    - Automatic installation of pre-commit hooks for code quality
    - Automated authentication for internal systems
    - Tools that manage cloud workstation usage (e.g., auto-shutdown for workstations)
- **Documentation**: We invest heavily in documentation, running quarterly "docathons" to ensure our work is adequately documented for future team members. As I like to say, "Software scales labor, documentation scales brains."
- **Modern dependency management** with tools like pixi and uv.

These standardized practices reduce cognitive overhead. If I jump into a colleague's project, I immediately know where to look for documentation and tests, which helps me onboard faster than having one-on-one sessions. Shared idioms and patterns make it easier to jump in and help each other, fostering stronger team dynamics.

Notice that it's not really about the tech – it's about the practices. The goal is for scientists to spend less time on configuration and more time on science. The investment of my time hopefully yields thirty, sixty, or a hundredfold in terms of what we give back to our teammates.

### 3. Implementation Strategy

Change management principles apply to workflow standardization. Successful implementation requires both technical and cultural elements.

Our standardization journey at Moderna involved several key elements:

- **Leadership buy-in was critical**: The support chain included my direct manager Andrew Giessel and Dave Johnson, our Chief Data and AI Officer. When I implemented our standardized project structure, Dave personally reviewed the pull request. His comment – "I love the user-facing emojis" – showed me he had actually read my code and was supportive of this change.
- **Evolution through multiple iterations**: We started with a basic template that codified our best practices, each time making things better. Because we have so many repos flying around, we don't worry about upgrading all of them at once, but instead opportunistically update them when we get back to touching them.
- **Empowering others to contribute**: If someone finds a pain point, I guide them through the process for improving our command-line interface tools. The benefit is that shared knowledge grows and spreads.
- **Documentation of ways-of-working**: We leverage our two-day quarterly docathons to improve documentation for the long haul.

The command-line tooling we've developed isn't just my project – it's now shared with the ML platform team, and data & computational scientists actively make code changes to it. We "dog food" our own tools, which is incredibly empowering. You've got to give power back to the frontliners so they can make the changes they need to move at the speed they need.

Sustainable change requires leadership support, frontline champions, visible benefits, and evolution at a pace teams can absorb.

## Balancing Standards with Innovation

The perceived tension between standardization and creativity is often a false dichotomy. Well-designed standards actually create freedom through constraints.

At Moderna, we've found this balance by being intentional about where we apply standards:

- **Areas where we enforce standards**:
    - Project structure and organization
    - Deployment pipelines and processes
    - Documentation formats and expectations
    - Code review and quality check workflows
- **Areas where we preserve flexibility**:
    - Algorithm selection and implementation
    - Analysis approaches and methodologies
    - Visualization choices and design
    - Local development environment preferences

The key insight is focusing standardization on interfaces, not implementations.

This approach enables creativity in several powerful ways. By eliminating decision fatigue on routine aspects of projects, scientists no longer waste mental energy on trivial choices. The reduction in cognitive load from context-switching between different project structures allows deeper focus on the science itself. As automated processes handle repetitive tasks, teams gain valuable mental bandwidth for tackling complex scientific challenges. Onboarding and collaboration become significantly faster when scientists don't need to spend time explaining basic project organization. Finally, predictable workflows create an environment where scientists can anticipate next steps rather than inventing them anew each time, allowing creative energy to flow toward innovation rather than infrastructure.

## AI-Assisted Coding

Though not a focus of my talk, some folks asked about AI-assisted coding. This is completely ingrained at Moderna – everyone has access to ChatGPT Enterprise (that's public knowledge), and every developer who asks for GitHub Copilot gets it. We're developing extensive documentation on how to productively use AI assistance in daily coding.

The testimonials are powerful. Just yesterday, I interviewed a DevOps engineer who's doing three to four people's worth of work and coasting because of GitHub Copilot in agent mode. It's the ultimate productivity tool if you know how to wield it properly.

## Final Thoughts

What's particularly powerful about our approach is that it can be implemented **with minimal vendor dependencies**. At Moderna, our data science and deployment infrastructure is built almost entirely on open-source tools — our only significant software expenses are AWS, GitHub Enterprise, and GitHub Copilot. This deliberate choice to avoid vendor lock-in provides significant cost savings and the flexibility to adapt quickly as the scientific computing landscape changes.

The ultimate goal isn't standardization for its own sake — it's creating an environment where data scientists can do their best thinking and most innovative work. When done right, good standards don't constrain scientists; they liberate them.

It's taken three and a half years of my life at Moderna to build this culture, but it's been worth it. I'm optimistic about our future regardless of the stock price – I'm long on the technology.

Thanks for coming to my TED Talk! :)

_If you're interested in learning more about our compute platform at Moderna, my colleague Anand Murthy spoke about "Powering AI/ML at Scale: Building a Cloud-Native Infrastructure for Biopharma Innovation" on Friday at the same conference._
---
pub_date: 2025-04-02
---
twitter_handle: ericmjl
---
summary: In this blog post, I share insights from my talk at BioIT World about leading one of Moderna's data science teams. I discuss our mission to make science run at the speed of thought and how we standardize workflows across the data scientists to enhance creativity. Key points include designing delivery models, making best practices easy, and balancing standards with innovation. I also touch on AI-assisted coding and our open-source infrastructure. Our approach aims to liberate scientists for their best work. Curious about how we achieve this balance and what it means for the future of data science at Moderna?
---
tags:

data science
leadership
workflows
best practices
software
change management
innovation
ai
open source
