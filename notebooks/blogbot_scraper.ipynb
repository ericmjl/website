{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# import urlopen \n",
    "import requests\n",
    "\n",
    "\n",
    "# I want to scrape out the blog URLs from here: https://ericmjl.github.io/blog/\n",
    "# use the BeautifulSoup library to parse the HTML\n",
    "\n",
    "url = 'https://ericmjl.github.io/blog/'\n",
    "response = requests.get(url)\n",
    "html = response.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find all of the <a href> tags with \"Read on...\" in the inner HTML\n",
    "links = soup.find_all('a', href=True)\n",
    "links = [link for link in links if 'Read on' in link.get_text()]\n",
    "\n",
    "# compose the URLs into a list of strings\n",
    "urls = [url + link['href'] for link in links]\n",
    "\n",
    "# Find the <a> tags nested within the <header> tag\n",
    "header = soup.find_all('header')\n",
    "titles = [h.get_text().strip(\"\\n\") for h in header]\n",
    "anchors = [h.find(\"a\", href=True) for h in header]\n",
    "hrefs = [url + a.get('href') for a in anchors]\n",
    "# dictionary of link to title\n",
    "links_to_titles = dict(zip(hrefs, titles))\n",
    "links_to_titles\n",
    "\n",
    "\n",
    "# links = header.find_all('a')\n",
    "# titles = [l.get_text() for l in links]\n",
    "# titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "website",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
